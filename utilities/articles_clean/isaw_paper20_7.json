{
  "articleId": "isaw_paper20_7",
  "text": "ARTICLE_ID: isaw_paper20_7\nThere is a surprising number of manuscripts which still wait for any form of description and cataloguing. A large number are catalogued and a smaller but still very significant and increasing number are digitally catalogued.There are also many ways to catalogue and digitally encode catalogue information about manuscripts.Several of the institutional repositories which digitally catalogue manuscripts in their collections are also producing RDF (Resource Description Framework) and Linked Open Data for manuscripts in different ways and for different reasons.2 This chapter will deal with none of these.Instead, this contribution will present one possible way to produce RDF and Linked Open Data for a specific kind of information about manuscripts.3 Starting from a specific set of needs within a project, it will focus on the subset of RDF triples generated to answer these needs according to a specific ontology empirically designed to support a specific methodology for the study of manuscripts, namely the one described in the book La Syntaxe du Codex. Essai de codicologie structurale (Andrist, Canart, and Maniaci 2013) henceforth La Syntaxe.This chapter will not try in any way to give an overview of how to encode manuscripts or to describe a potential ontology for the description of manuscripts.The amount of information that can be gathered from a single manuscript, from the many points of view from which it can be analyzed, is overwhelming for any data modelling attempt which does not have a cooperative international team at its basis4 and I am not here calling for a comprehensive ontology for the description of manuscripts. Conversely, this chapter will focus on the specific needs of a selected methodology and show how RDF and Linked Open Data can support it in connection with other data formats.The chapter supports the heuristic potential of the solid and theoretically grounded research methodology as presented by its authors in La Syntaxe (1.2) and presents here only how, within the project Beta mau1e63u0101u1e25u01ddft, Manuscripts of Ethiopia and Eritrea (1.1), Linked Open Data is used to support the exploitation of this methodology for research purposes in a digital environment. The RDF triples produced (3)5 are used in the project, together with the core TEI encoding of the data (2), not just for the representation of the results of the research process but along the research process, to facilitate the analysis of the ground data and the formulation of interpretative hypotheses and to support different collaborative interests.Four examples of the digitally based research workflow will be given (4.1, 4.2, 4.3, 4.4) and two examples will be provided to show how the method described is used to encode events relative to the binding (4.5 Example Application 1) and to clarify how the different hypotheses are encoded and visualized progressively (4.6 Example Application 2) as the research process progresses.The practical starting scenario at the origin of the digitally based research workflow described in this article is quite simple. Let us imagine for example that the same manuscript is studied by a codicologist for a catalogue, then by a book historian interested in the production of the artefact, later on by a specialist in decorative patterns and miniatures and then by a philologist interested in some of the intellectual contents.6 The observations and annotations of each of these specialists should find their place and converge to an increasingly diversified understanding of the manuscript (Michelson 2016b, 160u201361), without affecting the specificity of the types of analysis and intents of the collection of information by each researcher. Linked Open Data (LOD) serves this scenario very well with its flexibility and lack of hierarchy and at the same time it crosses the boundaries of the adopted encoding or data storage technologies allowing projects with different aims and scope to interoperate.The drafting of the ontology presented here was motivated and carried out in response to the practical issues of encoding and cataloguing faced by the project team, some of which are presented in the examples. The test implementation started after the workshop Linking Manuscripts from the Coptic, Ethiopian and Syriac domain: Present and Future Synergy Strategies, held in Hamburg at the end of February 20187 with the aim of setting the basis for actual interoperations between the involved projects, which culminated in a proposal to produce RDF data about manuscripts and literary works capable of supporting federated queries across the dataset independently from the implementation technologies chosen.The questions of representation of information, as presented in the examples below, are all related to the history of the manuscript and its stratigraphy. The starting point is thus the understanding of a manuscript as a complex object which carries signs of the changes it incurred into, which can be read by scholars to identify stages of its history and thus access also information about earlier manuscript units which might not exist anymore but whose production or circulation is attested in the manuscript being observed, and studied (Andrist, Canart, and Maniaci 2013, 7u20139).The driving motivation is to describe the manuscript with only the necessary minimal annotations to be able to access and navigate both the description of the current object and the different stages of its history without having to reconstruct a description for each of them. It is indeed a very practical need, grounded also in the necessity not to waste time during the project.On the other side, it is a methodological need, which requires us to offer data in the most complete and most simple and clear way.Although the reading of the book is essential to the understanding of the methodology and it is not my intent to try to summarize it, let me attempt to highlight right here at the outset what I believe to be the key concepts on which La Syntaxe is based (Andrist, Canart, and Maniaci 2013, 7; Andrist 2015, 511) some of which will be better described in the following sections,A medieval codex is a complex object from its origin and is subject to many changes during its life; it carries most of the time traces of these changes which the scholar needs to be trained to identify methodically.The analysis of a manuscript identifies primarily discontinuities and different categories of elements constituting the codex. Elements can be grouped into Units of different kinds which are meaningful.The identification of concomitant discontinuities supports the identification of codicological units.The concept of codicological unit is refined into production units (UniProd) and circulation units (UniCirc).This core theoretical distinction allows to describe the manuscript (indeed not only the codex) history clearly and effectively.The stratigraphy of a codex can be studied systematically but needs a new approach and new eyes, familiar to the signs of the transformation and able to read the language these signs speak (Andrist 2015, 511).The syntactic description of the codex, which is the outcome of the syntactical and stratigraphic study of its complex structure reflects the history of all the units which have been added, subtracted andor modified in the course of its history and accounts for the depth of the tradition, giving us virtually access to the units which are not there anymore and thus allowing us to describe them in their proper relation to the object we are studying. The ways in which the adoption of this methodology is reflected in the design of a database or is presented online or in print is a different order of problems (Andrist 2014, 2015; Gippert 2015) and this article is concerned mainly with the first of this secondary problems.The examples proposed should be taken as a work-in-progress description of temporary results for the project Beta mau1e63u0101u1e25u01ddft: Manuscripts of Ethiopia and Eritrea, which has provided the examples which have led to the development of the ontology and the implementation of the workflow based on La Syntaxe. The examples are meant to illustrate the workflow design, not to provide a definitive description of the manuscripts.The project also does not apply systematically at this stage the method proposed in La Syntaxe, being in a phase where catalogue descriptions are encoded from existing catalogues which used old and very old methodologies, different from one another and harmonized thanks to their TEI encoding.8 Taking a realistic approach, we want to be able to apply the method as far as possible, without redoing all description from scratch. We want to allow researchers to look with new eyes at the existing data and build on top of it using the conceptual and practical tools offered by La Syntaxe.I will outline in the following two subsections of this introduction the project in which this study has been based, Beta mau1e63u0101u1e25u01ddft, and give a summary of some relevant concepts in La Syntaxe.In the second section, the reader will find a description of how the TEI encoding is used in the project to produce RDF triples and the method used to map TEI to RDF. The third section includes the description of the translation of the methodology described in La Syntaxe into OWL (Web Ontology Language).The fourth section contains four real-life examples and two more complex applications which demonstrate how the methodology supports the research process and collaboration.The final section highlights the potential of this model with some examples of queries.1.1. Beta mau1e63u0101u1e25u01ddftThe project Beta mau1e63u0101u1e25u01ddft: Manuscripts of Ethiopia and Eritrea Schriftkultur des christlichen u00c4thiopiens und Eritreas: Eine multimediale Forschungsumgebung9 (hence Beta mau1e63u0101u1e25u01ddft, which means 'library') is currently encoding already existing catalogues of Ethiopian manuscripts10 while building the first Clavis Aethiopica and a digital gazetteer of ancient places in Ethiopia11 based on the Encyclopaedia Aethiopica (Uhlig and Bausi 2003u20132014).12 All data is encoded in TEI,13 following in many respects the model set by the Syriaca.org project (http:syriaca.org). The project aims at offering to all different specialists in the field the possibility to use the resources for their purposes and to allow them to collaborate easily in the encoding and digitization of resources relevant to this field of study.Beta mau1e63u0101u1e25u01ddft has already benefited from active collaboration with major projects and institutions involved in the study of ancient Ethiopian manuscripts14 and from the constant collaboration with the Centre for the Study of Manuscript Cultures15 in Hamburg.The current phase of the project deals with the encoding of already catalogued manuscripts, which requires in most cases a thorough rethinking of the description of the manuscript. Fortunately, many images of these manuscripts are now available online,16 and many more are becoming available thanks to the effort of many projects, people and institutions.This fact allows the team to revise many statements which together with the critical act of encoding the available description results in providing what is a new codicological description, not a digitization of existing works. Additionally, the team also performs an assiduous identification and verification work, linking each named entity (e.g. a date in a text, a toponym, a personal name attested in the text) to an authority file which has the core data about that entity.The following example is a colophon from Paris, Bibliothu00e8que Nationale de France, BnF u00c9thiopien 80 (Reule 2016b).tu1260u12a0u12b0u1274u1270u1361 u12a5u130du12dau12a5u1290u1361 u12a2u12e8u1231u1235u1361 u12adu122du1235u1276u1235u1361 u1270u133du1215u1348u1275u1361 u12dbu1272u1361 u1218u133du1210u134du1361 u12a0u1218u1361 <date calendar=grace>u137bu1377u12c8u136fu1361 tu12d3u1218u1270u1361 u121du1215u1228u1275u1361<date> <date type=evangelists>u1260u1218u12cbu12d5u1208u1361 u1209u1243u1235u1361 u12c8u1295u130cu120bu12cau1361<date> u12a0u121cu1203u1361 u12a0u1260u1245u1274u1361 u136cu1361tu12c8u1218u1325u1245u12d5u1361 u1373u12c8u136fu1361 u12c8u1270u1348u1338u1218u1275u1361 u1260<placeName ref=Q1218>u12a2u12e8u1229u1233u120cu121du1361<placeName> u1200u1308u1228u1361 u1230u120bu121du1362 tu12a0u1218u1361 <date>u1373u12c8u136du1361 u1208u1218u1235u12a8u1228u121du1361 u1260u12d5u1208u1270u1361 u12d0u122du1265u1361 u130au12dcu1361 <gap reason=omitted extent=unknown resp=PRS10747Zotenbe> tu1230u12d3u1270u1361<date> u1218u12d3u120du1275u1362 u1260u1218u12cbu12d5u1208u1361 u122bu12edu1235u1361 <persName ref=PRS11115FereKr>u134du122cu1361 u12adu122du1235u1276u1235u1361<persName> u12c8u120du12f0u1361 u12a0u1261u1290u1361 t<persName ref=PRS11208HouseTakla>u1270u12adu1208u1361 u1203u12edu121bu1296u1275<persName>u1362 u12c8<persName ref=PRS11116GabraN>t<roleName type=title>u1218u130bu1262u1361<roleName> u1308u1265u1228u1361 u1296u120bu12cau1361<persName>Although the articulation of the project schema based on TEI supports most of the needs of the team, there are cases which have been encountered in these first two years which have led us to rethink some of the encoding and indeed the cataloguing practice. There was especially the need to describe more than one of the stages in the life of a manuscript, or to state that a physical part was added at some point, without being able to say more in terms of when, how, etc.La Syntaxe offered us a solid theory and a clearly described methodology on which to base our practical solutions.We have decided to try to support in our workflow all the phases of the research process described in the book, although at this very early stage of development and testing we have probably still a lot to refine.17 We can now turn to see very briefly what these stages are and what the methodology looks like, to then move on to describe the way its usage is translated in the workflow for Beta mau1e63u0101u1e25u01ddft.1.2. La Syntaxe du CodexA very useful and reasoned State of the art in codicology can be found at the beginning of La Syntaxe (Andrist, Canart, and Maniaci 2013, 11u201344).This work can be complemented with parts of the COMST Handbook (Bausi et al. 2015) for the represented oriental traditions and also with the introduction to a recent volume about composite and multi-text manuscripts (Friedrich and Schwarke 2016).La Syntaxe is a book where examples are based on Greek and Latin manuscripts, but the proposed methodology can be applied, with necessary adjustments, to any manuscript, including papyri, palm leaves, etc.18 It is the simplicity and clarity of the research process it describes that makes it so powerful. The observation stages are thought of in a way that bases the resulting analysis of well-structured observation data.The tabulation stages of the observation which help highlight concomitant discontinuities (see below) are then translated into an event-oriented description (Du codex observu00e9 u00e0 la reconstruction de son histoire is the title of the fourth chapter).The methodology aims to mettre en relation ces u00e9lu00e9ments pour comprendre comment le codex 'tient ensemble' et se modifie avec le temps [tr: bring together these elements to understand how the codex takes shape and is modified over time.] (Andrist, Canart, and Maniaci 2013, 9), which is precisely what we needed to encode in the project Beta mau1e63u0101u1e25u01ddft.The methodology, whose ground concepts have been stated in the first section of this introduction, starts with the definition and identification of discontinuitu00e9s (discontinuities) which identify u00e9lu00e9ments (elements) and potential unitu00e9s (units). An element19 is necessarily comprised between two discontinuities (including the beginning and the end of the manuscript).An element corresponds to one or more of the observable discontinuities of one category and a unit corresponds to one or a series of elements (not necessarily adjacent) and is the meaningful building block of a description (Andrist, Canart, and Maniaci 2013, 83) of a category as a stage towards the final description of the manuscript. The models to which a series of units can correspond are the actual real-world-things and are both the starting point of the observation and the result of it: the cataloguer sees that a manuscript is composed of one material throughout, e.g. parchment, and will know that it is a Modu00e8le Mat 1, where there is one material element, which corresponds to one material unit (Andrist, Canart, and Maniaci 2013, 85);20 a cataloguer could equally assign one UniMat to the entire manuscript or assign it to the Mat1 class directly to conclude that it is an instance of the Modu00e8le Mat 1. For example, most Ethiopian manuscripts are made entirely of parchment and can be treated this way, unless some further research is made and for example, it is found that the parchment of a part is obtained from one animal species and the parchment of another part comes from a different one, which might lead to distinguish two UniMat, if relevant.Core concepts defined in La Syntaxe are the 'Unitu00e9 de Production' (production unit, hence UniProd) and the 'Unitu00e9 de Circulation' (circulation unit, hence UniCirc) (Andrist, Canart, and Maniaci 2013, 59u201362). Every change occurring to the structure produces one or more circulation units and possibly one or more production units.These are the meaningful stratigraphic units.There are three main stages in the methodology (Andrist, Canart, and Maniaci 2013, 8):21List discontinuitiesAdd to a flat list.22Draw a table where converging discontinuities (discontinuitu00e9s convergentes) are visible.Enrich the table with chronological and geographical information to verify the relevance of the discontinuities and consequently recognize production units and circulation units (see below).Go back to the manuscript to check theoretical results with archaeological analysis.In the process of formulating a hypothesis in step 2 the researcher will start from UniProd and UniCirc 'Hypothetique', UPH and UCH (Andrist, Canart, and Maniaci 2013, 111). These will become certain only once the process is completed, or until new evidence can challenge the statements made.The stages of the methodology are supported in a digitally based workflow like the one of Beta mau1e63u0101u1e25u01ddft not only by RDF, but also from the actual format of the underlying data, TEI, and by the visualization technologies used.23The first step of the methodology (point 1a in the list above), which involves the observation and encoding of the information about the manuscript and its discontinuities, can be accomplished by encoding in TEI the information available and be made in such a way that it benefits of the structure of the TEI tree (i.e. it is not simply a flat list). The second step (point 2 in the list above) and the table visualization (point 1b in the list above) can be achieved directly from TEI (Stokes 2015a, 2015b) but also from an RDF representation with the advantage in this case of drawing from any relevant statement taken individually, and free of its hierarchical definition.This stage involves the assignment of UniProd and the definition of potential UniProd and UniCirc to be verified in the third stage (point 3 in the list above) and these two steps (2 and 3 in the list above) need to be repeated as many times as required for each working hypothesis.Together with the description, we want here to formally encode also the statements about the hypothetical reconstruction of the UniProd and UniCirc involved. There are thus two kinds of information:the identification of discontinuities and the verification of their relevance andthe reconstruction hypothesis.The latter are relational statements in nature and are much better represented in an RDF graph (as in the book, see Fig. 1).However, to be able to iterate the process in one workflow also these hypotheses need to be encoded in the TEI as the description. The researcher will thus only produce TEI, for both purposes and this will be transformed into RDF.The RDF becomes invisible in the workflow.Fig 1.The graph-like representations of the transformation models in La SyntaxeThe methodology translates then in the digitally based workflow into the following steps, where numbers identify researcher steps and letters steps performed by the software.The production of the visualizations is done from the RDF which is produced behind the scenes for both descriptions and hypothesis (as we shall see in the example of Bern, Burgerbibliothek, Cod. 459 below). Adding element nodes to the TEI description means at the same time adding graph nodes to the RDF and being able to use them in the statements which build the hypotheses, but as little inferences are made as possible and there is no intent to magically transform a flat description of a manuscript in a syntactic description: this can be done only by the researcher and the current workflow tries to support himher in doing this. Only the cataloguer can decide if to make and add a statement which relates a particular element or unit to a UniProd and a particular UniCirc and will do that in the TEI either enriching the description with more nodes or by adding a relation.The enriched table (Fig. 2.1) representation needs also to follow some logic and apply some rules which will be part of a script.For Beta mau1e63u0101u1e25u01ddft, at the moment we use a simple JS script which takes the results of a SPARQL query (Harris and Seaborne 2013) and transforms them into a table as we will describe below as an example. On-demand the table is then enriched with more data which is taken this time directly from the TEI (Fig. 2.2).Fig. 2.1.Table of Units exampleFig. 2.2.Example of enriched table of unitsThe enrichment of the table can be drawn on the information available in the TEI encoded description, but also from the wider graph of relations available in the RDF, leading to revisions of the TEI encoding or additions to that description. Images can also be added to the table view if they are available.In Beta mau1e63u0101u1e25u01ddft, the TEI description of the manuscript is also used to generate a Manifest according to the IIIF Presentation API25 and the <locus> element with its attributes can be used to retrieve the correct image.Date, references to persons or places and other information are added only if directly linked to the unit, for example, if they are inside the relevant element, and they are applied to the minimal possible scope. For example, the date in a colophon, unless explicitly related by a triple to the entire manuscript, is only associated with the unit to which the colophon belongs.26In the following section, we will look at the first part of this implementation of the workflow, i.e. how the observation of the manuscript as described in La Syntaxe and the hypothesis are encoded in TEI.Section 3 will then describe the structure of the RDF data produced from the TEI which uses classes and properties of the ontology-based on La Syntaxe and the following examples will describe how the statements about the stratigraphic reconstruction are produced.2. Using TEI to encodeAs we have seen in the previous section, we have two sets of information to encode, the description of the elements and units on one side and the hypotheses on the relation between the units (especially UniProd and UniCont) on the other.The first of these tasks is achieved well in TEI, the second calls for a graph data structure.We have also seen how we need to have for different workflow purposes both types of information encoded in TEI, but we also want to have both available in RDF, so that we can use the graph and we can point to entities in the description. The process of getting the entities in RDF which will allow anchoring the triples with the hypothesis is a prerequisite to be able to do that at all.We need then to transform some of the nodes in the TEI encoded description into triples which can be used to make statements according to La Syntaxe in the hypotheses formulation stages.Mapping TEI to the elements and units used in La Syntaxe for the description of the manuscript is an intellectual exercise which might seem as disappointing as it is tedious. La Syntaxe is a modu00e8le interpretatife (Andrist, Canart, and Maniaci 2013, 44), not a descriptive markup like TEI or a Conceptual Reference Model like the CIDOC-CRM or a data model in a relational database.27There are indeed nodes in TEI which contain quite exactly the information regarding a specific discontinuity, for example, a <layout> or a <handNote> which give the information about a specific layout in the manuscript, eventually also with the indication in a <locus> element of the physical location of the discontinuity. They can in most cases be equated respectively to Unitu00e9s de mise en page (UniMep) and Unitu00e9s de mains (UniMain) using the abbreviations in La Syntaxe.The <locus> element is pivotal to all the described process as it provides the coordinates of a phenomenon and its attributes @from, @to and @target are used to provide the actual ranges or exact locations of phenomena.FAs there is often no <locus> as the information is given generally, it is not so obvious to which part of the manuscripts this refers to when we translate it to a UniMat. However, in Beta mau1e63u0101u1e25u01ddft, this is by far the most common situation28 and if no other statement is available, we can assign this Unit to the entire extent of the manuscript part in which this markup occurs declaring one UniMat (which would also correspond to an u00e9lMat).We use systematically <msPart> and <msFrag> in the description, which means that the scope of this information is already specified (see 4.4).Some entities simply cannot be equated to a node in the TEI description like a UniProd or a UniCirc, given that the TEI documents a manuscript with its transcription as in Beta mau1e63u0101u1e25u01ddft. Adding these as elements in a TEI schema would be of little help and only contribute to making the TEI less canonical. A UniProd or a UniCirc define an entirely different semantic concept.However, one could assume that the manuscript as we have it in our hands is always a UniCirc and at least one UniProd.But we cannot instantiate this as a specific UniCirc or UniProd in the description of the manuscript, we can only state, after analysis of a given set of information, that it is in one or the other or both of those classes, without any specific identification, which is a partial statement that we can reuse later in the process.There are also units in La Syntaxe which are described by more nodes in the TEI (including the example for UniMat above) or by nodes which are made unambiguous by their path in the XML representation but once extracted and transformed into a non-hierarchical structure might lose this characteristic and need their specification. For example, in our TEI descriptions we use the element <item> as a descendant of <collation> for the description of each quire, and as a descendant of <additions> for each addition or extra in the manuscript.These nodes need to be evaluated in the conversion from TEI to RDF so that they remain distinguished, and we will see below which technique we have used to achieve this.Let us take the example of the manuscript contents. There are three terms defined in La Syntaxe: Contenu, texte, u0153uvre (Andrist, Canart, and Maniaci 2013, 51).The first is defined as 'le message qu'il transmet u00e0 travers un ensamble de signes' [tr: the message that it [the manuscript] transmits through a series of signs] and is then distinguished in contenus principaux (u0153uvres ou copies d'u0153uvres, images, du00e9corations, partitions musicales, un mu00e9lange de celles-ci, des notes marginales sur un texte...) [tr: main contents (works or copies of works, images, decorations, musical notations, mixtures of these, marginal notes on a textu2026)] and contenus accessoires (notes de possession, cotes du manuscrit, graffiti, probationes calami, obit, marques de succession) [tr: additional contents (ownership notes, cotes du manuscript, graffiti, probationes calami, obit, succession marques)]. These find in a TEI description (TEI Consortium, Sperberg-McQueen, and Burnard 2018) of a manuscript their distinct places quite easily:Contenu principaux = <msItem>s in <msContents> (manuscript item) describes an individual work or item within the intellectual content of a manuscript or manuscript part.Contenu accessoires = <item>s in <additions> contains a description of any significant additions found within a manuscript, such as marginalia or other annotations. This might encompass a list of items, one for each such addition.But since the u0153uvre is a 'production organisu00e9e de l'esprit, consideru00e9ru00e9e dans un sens immatu00e9riel' [tr: organized production of the spirit, considered in its immaterial sense] there needs to be a distinction between the exemplaire in the manuscript and the u0153uvre.This is achieved in Beta mau1e63u0101u1e25u01ddft by having the works in separate records referenced from the TEI description of the Manuscripts, a common solution for the data architecture used also by many other projects.29There will be then two types of TEI files, one describing a manuscript and one describing a work. Each of these TEI encoded entities will contain a tagged description in XML of the manuscript or of the work with its editions.All elements at all levels could be an entity and have their own URI, but this is not always practical.In Beta mau1e63u0101u1e25u01ddft we give organized and structured xml:id attributes to the elements in the TEI files which have a specific status as a relevant and referenceable entity in the description. In manuscripts, for example, the elements <handNote> and <decoNote>, but also <msItem> and even the very generic <item> element, when this is used as in the example below to include information about the additions; or <div> if it encodes a meaningful part of a transcribed text.When creating RDF and entities with URIs,30 this simple encoding practice allows assigninga URI to a literary work (u0153uvre),a URI to a manuscript,a URI to the main contents (exemplaire) of the manuscript, i.e. that copy of the intellectual work, as a <msItem> to which we have assigned an ID,a URI to each additional content.31For example in Beta mau1e63u0101u1e25u01ddft encoding of Vatican City, Biblioteca Apostolica Vaticana, Aeth. 1 (Villa and Reule 2016) and the Gospel of Luke (Villa 2017)The Gospel of Luke as an abstract and organized intellectual product (u0153uvre) is the entity https:betamasaheft.euLIT2713Luke;The Biblioteca Apostolica Vaticana Ethiopic Manuscript 1 is a manuscript, the entity https:betamasaheft.euBAVet1;The Gospel of Luke in the above manuscript is the entity32 https:betamasaheft.euBAVet1msitemms_i1.4.2;The Calendaric note on folio 219r is the entity https:betamasaheft.euBAVet1additiona3Additionally, each of these is assigned to a class (and it can be added to as many as one wishes)https:betamasaheft.euLIT2713Luke is an instance in the class http:lawd.infoontologyConceptualWork 'The idea of a work, which may have any number of written expressions (which may themselves have derivatives)';33https:betamasaheft.euBAVet1 is an instance in the class http:lawd.infoontologyAssembledWork 'A Written Work that collects together more than one Written Work. Manuscripts are often AssembledWorks';34https:betamasaheft.euBAVet1msitemms_i1.4.2 is an instance in the class https:betamasaheft.eumsitem which includes contents of a manuscript and might be an instance in the class UniCont;https:betamasaheft.euBAVet1additiona3 is an instance in the class; https:betamasaheft.euaddition which includes all the contents which have been encoded like additions because they have that status in the manuscript being described and might be an instance in the class UniCont.This loads on the @xml:id attributes present in a TEI file a further requirement (which we enforce also in our project schema) not just to be unique but also to contain some semantic information. In Beta mau1e63u0101u1e25u01ddft a <handNote> will always have an ID starting with 'h', an extra has to have an ID starting with 'e' and a title needs to start with 't', for example, so that from the id and knowing the schema and guidelines, one can tell what he is looking at.In the example above we have seen the ID of a <msItem> and this contains also information about the actual position of the node35 in the description, telling us that the node with ID ms_i1.4.2 is the second <msItem> inside the fourth secondary level <msItem>, inside the first main level <msItem> of <msDesc>. One could eventually also build an XPath expression from this, like msDescmsContentsmsItem[1]msItem[4]msItem[2].The ID tells us also that this manuscript does not have <msPart>s as this content unit is inside <msDesc>. A content item of a <msPart> would have had according to the project guidelines an ID of the kind p1_i1.4.2.These standardized IDs allow also to create further ones and rely on them for the transformation. For example, assigning an ID starting with tr will result in the process (the XSLT transformation producing the RDF XML)36 in creating an entity for a Transformation; assigning an ID starting with UniCirc will result in the process in creating a circulation unit with that ID, both of which correspond to no element or fragment of description in the TEI but exist as nodes in the graph representation.37There are then a series of information which can be encoded in the <relation> element in a TEI description.38 This is defined as follows, (relationship) describes any kind of relationship or linkage amongst a specified group of places, events, persons, objects or other items39 and uses attributes which make of it an ideal candidate to store triples directly in TEI as documented also in the examples of the guidelines.40 In Beta mau1e63u0101u1e25u01ddft, it is used for example to state the relationship between different versions of a given conceptual work and it is used to encode all the relations needed by the methodology of La Syntaxe. This will be shown in the examples below but we need first to see how the methodology is converted into an ontology that can be used to produce such annotations and statements.3.From TEI to RDF: La Syntaxe as OntologyAs already stated, La Syntaxe is much more than a methodology, it is also an ontology in the semantic web meaning of this word, describing classes and properties as well as guidance in how to properly make use of them.The process of translating it into a formal ontology in OWL is thus simple in its first stages. Each unit and each transformation is a class, organized as described in the book and there need to be then basic object properties relating such classes.Fig 3.2.Ontology property in Protu00e9gu00e9It is much easier to handle this code with an interface and look at it with a software application like Protu00e9gu00e9 as shown by Figs. 3.1 & 2, though I show the raw RDF so that readers can confirm that the very same structure for triples is used.This ontology alone does not serve any purpose without reading and understanding the book, its only purpose is to allow the annotation of statements made following La Syntaxe.The classes are organized in the following way. UniCirc and UniProd are the most important top classes, and UniProd has subclasses UniProd-C, UniProd-C-MC, UniProd-M, UniProd-MC.These, as constituents of the main description, do not have subclasses and are related to Units and Models with specific properties.Other two special main classes are Certain and Hypothetique.The other top classes represent the core concepts of the methodology:Transformation, which has subclasses simple and multiple each of which lists the main typologies as in the book,Modele, which contains as subclasses all the models for each unit,Unit where only the main unit type is a class and the relative element is a subclass of it,Stratum, which contains the 4 types of strata defined in Andrist 2015, 512.42Whilst all classes are only taken from the book, the object properties have been defined by myself based on an economic principle and are the following:constituteUnit which relates a unit (or more) to a UniProdcontainsUnits which relates UniProd and UniCirc to other unitshasCertainty used to assign the classes Certain or Hypothetique to a given UniProd or UniCirc (although Hypothetique should be assumed where no information is provided)undergoesTransformation which connects a UniProd or UniCirc with the Transformation in the objectproduces which connects a Transformation to its resulting UniProdresultsIn which connects a Transformation to its resulting UniCirc (or UniProd)hasTransformationModel which defines for a Transformation a given modelhasTransformationPart and isPartO fTransformation which relate two or more Transformations to a complex TransformationhasUnitModel which relates a Unit to a ModelisStratumOf used to connect a defined stratum to a UniCirchasStratum used to define a stratum of a UniCircNone of these statements is in any way mandatory.One could have any discrete piece of information to provide and it would be fine.Units constitute UniProd and UniCirc which undergo transformations to produce other UniProd and UniCirc. Any of these should be analyzable as an entity in its own right, without duplicating the descriptions for this purpose.It has to be said that for the methodology to be used a series of other statements need to be available, which are taken from the TEI description and mapped to RDF statements, but are out of the scope of the current contribution.For example, the equation between two concepts which is established using the SKOS43 property skos:exactMatch and the physical location need also to be known and at the moment for Beta mau1e63u0101u1e25u01ddft, we produce statements using a local vocabulary,44 although alignment with existing efforts is what we are aiming at.In our current RDF, we choose to use dcterms:hasPart as a property that relates the manuscript to its parts but also any units. dcterms:hasPart also relates a part to its assigned contents and each entity can be assigned, based on the locus element values, the local properties bm:locusTarget, bm:locusFrom and bm:locusTo, so that we can do a SPARQL query to retrieve any entity which is an instance of any of the SdC (Syntaxe du Codex ontology) classes with its locus if known and plot them in a table which lists them all, regardless of where they come from in the TEI encoding.The query could look like this:In the SELECT DISTINCT statement (1) I am declaring the names of the variables I want to use, prefixed with '?', this will be the headings of my table. (2) says that the resource I want to look for has a part, i.e. there is a triple which has exactly that structure. There will be many indeed, this is a very vague statement, so I am going to filter.The OPTIONAL statement (3) tells the query to take the triples if they are there.In this case, I am saying: if there is any placement information, then take whatever is there.There might be nothing, a target or more, from and to: if there is any of those, take it, if there isn't, do not worry.At (4) I am giving as a string the ID of the manuscript I want to look for, so that I can (5) filter all the resources to just the one I want. If '?resource' was not declared as a variable, but directly as <https:betamasaheft.euBNFet45> I would have of course not needed to do any of this. I then (6) filter all the results to get only the classes I want.The table produced will have all the SdC triples available for the manuscript BNFet45 (see examples below) which is not at all like the table in La Syntaxe.The example below gives only some results to make the table more explicitTo produce the table (see Figs. 2.1. and 2.2.) as described in La Syntaxe (Andrist, Canart, and Maniaci 2013, 113) the javascript will get the results of this query45 then, for each page, getting the total from the <extent> element of the TEI (1r, 1v, 2r, 2v, etc.) builds a table row with a column for each of the Units (we use also additions and decorations units) and if in the query results there are some with a unit which has a range matching that page, then the unit name is added to that column. Once the looping through all the rows is done, equal rows are collapsed updating the folios range to the correct one.Given that the RDF data has triples for each UniCirc which have been defined, a similar or even simpler query could be run to construct a graph only for a specific UniCirc.For example, if I want to have a graph which has all triples directly involving the main entity for manuscript BNFet45 (see section 4.4) I would do something like thisThe CONSTRUCT instruction (1) declares the shape I want the data retrieved to have, so I can go from one graph to another graph declaring a template for the data retrieved with WHERE (2). Here it will be just the same, I am using this to get as a response a graph instead of a result which uses the SPARQL Query Results XML format.What I want to highlight is that I can do the same about the UniCirc1 declared for it (see below Example 4).Note that I have just changed the subject of the statements.Fig 4.The same query with a UniCirc as a subject instead of a manuscriptI can get a description of each UniCirc starting from the observed data (see Fig. 3). With the second query in the example above, for a situation like the one in Example 4 (section 4.4), where some quires have been taken from BNFet45 to increase BNFet165, I will also have the <msPart> entity which is now part of BNFet165 because it was actually in BNFet45UniCircUniCirc1, whereas a query for the UniCirc2 in that example would return only one UniProd.We can access in the same way both stages of the history of the manuscript. To encode the different, documented, certain or hypothetical circulation units in the history of a manuscript, I need not prepare a description of the reconstructed manuscript and place it together with other real-world entities. I could also search for UniProd within a certain date range, which would not return manuscripts, but only the relevant production units.Now that the encoding has been described and some aspects of the ontology have been presented we can start to see how the methodology is supported in some of its stages by the TEI and by the triples extracted from it.4. ExamplesWith the following examples, we are actually in a special position of encoding the results of an existing observation.The cataloguer has performed with their tools and methodology an analysis and has produced a description which has been encoded in TEI.We will see how this encoded observation is transformed into RDF and visualized.464.1.Example 1 - Oxford, Bodleian Library, Bodleian Aeth. e. 8Our first example is Oxford, Bodleian Library, Bodleian Aeth. e. 8 (Reule 2017d), were none of the three <msPart> has an internal date and the dating is in general uncertain, but we know that <msPart> 1 and 2 were added later to the manuscript.The TEI, in this case, has an ID for each <msPart>, which is thus already recognized as a UniProd at this stage, and we have thus URIs for the three entities at play in this description.The RDF will contain only a relation between the manuscript (BDLaethe8) and its parts. Each statement should be something like 'BDLaethe8 has a part p1', where 'BDLaeth8' is the subject, 'has a part' is the predicate and 'part p1' is the object.Each of this is translated to a URI, which is local to the project for the instances and uses Dublin Core terms for the predicate.We will then haveSubject: https:betamasaheft.euBDLaethe8Predicate: http:purl.orgdctermshasPartObject: https:betamasaheft.euBDLaethe8mspartp1In RDF-XML, our three statements can be written as follows (which is the format we will be using, omitting the prefixes for the sake of brevity)It does not say explicitly that these are UniProd, because the cataloguer did not want to make that statement. Nevertheless, the information provided by the cataloguer is enough for us to hypothesize he is describing a transformation of the type A1: ajout de support matu00e9riel et de contenu [tr: addition of material support and content] (Andrist, Canart, and Maniaci 2013, 63) where both material support and contents are added to an existing UniCirc producing a new UniCirc.Given the encoding method described above, we could represent this in the TEI like in the following example.48Here we start defining only the part 3 as UniCirc, by giving it the ID 'UniCirc1' using the property sdc:constituteUnit from the ontology. The XSLT script producing the RDF will parse the ID to create an entity with that ID and assign it to the class sdc:UniCirc.Then we say that part 3 (UniCirc1) has undergone a transformation (property sdc:undergoesTransformation).During this process of transformation part 1 and part 2 were produced (sdc:produces) by this transformation, which resulted (sdc:resultsIn) the UniCirc2.Now that the two parts have come into the game, we can also explicitly assign them to the UniCirc2 with the property sdc:constituteUnit. To be consistent with the rest of the ontology describing the manuscript, of which you have a snippet above, we can also repeat the dcterms:hasPart nodes for each UniCirc.We are defining a transformation with ID 'tr1', which will become an entity and will be assigned to the sdc:Transformation class by the XSLT.Then we want to say that we know that this transformation is an addition of material and content, thus a transformation of type A1, and we do so using the property sdc:hasTransformationModel. The same transformation is the one producing the new UniCirc.Now that we have also this entity (but the order of the encoded elements is irrelevant, we are just following the logic in the argument) we can say that it is this one UniCirc with ID 'UniCirc2' which corresponds to the manuscript we have in our hands.We cannot make any further statement about UniProd or about the pertinence of the parts 1 and 2 to another UniCirc and we do not do so.The XML notation above produces the following triples in Fig. 5.1 (which are stored as RDF XML in our project).Fig 5.1. Oxford, Bodleian Library, Bodleian Aeth. e. 8 triples as viewed in the RDF validator (https:www.w3.orgRDFValidator)Each part is by default assigned also to the UniProd class, but without any entity to define this unit. A visualization of these nodes is given below (Fig. 5.2).49 Although the Certainty nodes are not in the example above for brevity, there is always the possibility to add these statements.Fig 5.2. Graph visualization of Oxford, Bodleian Library, Bodleian Aeth. e. 8For comparison purposes, I provide here also other two visualizations (Fig. 5.3), using a graphical visualization like the one in La Syntaxe (which I have made with PowerPoint), and in a Sankey chart, a common visualization of graph data.These charts are produced using Google Charts50 based on data queried from the RDF and seems to me to render well the reconstruction of the hypotheses about the history of the manuscript. The following is the query which is used for all the following charts of this type in the article.The results are transformed to the array or arrays required by Google Charts, i.e. again a simple table which describes the connection between entities only and in our case assigns a value to this relation.The relation name (the predicate) is not relevant for the production of this chart.First of all (1) I am declaring the variables, i.e. the columns headers for my table, and I only need to know from where and to where the connection goes. To each connection, I then want to additionally assign a weight, so that I can vary the size of the connections and provide graphically the diverse importance or type of connections.The WHERE statement uses UNION to collect together different types of triples. I want to take (2) anything which is related by a sdc:constituteUnit property, (3) anything which is related by a transformation (sdc:undergoesTransformation) but I am not interested in the transformation itself for this chart, so the variable ?transformation is used but ignored in the response, whereas I want to have all what results (3) or is produced (4) by any transformation. Finally (5) I want to have the relation with the actual codex, which is given with skos:exactMatch.Since I used always the ?from and ?to variables I can now filter those values (6) to get only the results which contain the identifier I want to query about in either of the two positions, as subject or object.These diagrams show UniProd and UniCirc belonging to the subject manuscript, which is explicitly related via one of four properties. Those linked by a transformation (in two steps) either as products or results are given weight 1.UniProd and UniCirc identity declarations (sdc:constituteUnit) are given weight 2.Exact matches are given weight 3.The latter could be omitted, but I am preserving them here for completeness.This might result in some superfluous nodes which have been kept here to allow reading the chart knowing the encoded nodes. There is no chronological implication, the chart represents the units in a flow.For a stratigraphic analysis, they should be read right to left, for a history of the manuscript left to right.Fig 5.3.Syntaxe transformation drawing and Sankey chart of Oxford, Bodleian Library, Bodleian Aeth. e. 84.2.Example 2 - Vatican City, Biblioteca Apostolica Vaticana, Cerulli 37This example uses the same type of encoding to represent an hypothetical assertion. This is simply done by assigning the entity which is not certain, in this case, a production unit to the class sdc:Hypothetique.In the encoded description of Vatican City, Biblioteca Apostolica Vaticana, Cerulli 37 (Valieva 2017), the editor says that a manuscript part has probably been added to the manuscript.The RDF will look after transformation like the tabular view in Fig. 6.1.Fig 6.1.Vatican City, Biblioteca Apostolica Vaticana, Cerulli 37 triples as viewed in the RDF validator (https:www.w3.orgRDFValidator).A class sdc:Hypothetique could have been associated with any statement, but here we will try to stick to the methodology described in the book and assign it to the UniProd. In this way, we are not putting in doubt the existence of the <msPart> as described in the TEI but only the fact it is a UniProd which was added to the other <msPart> with a transformation corresponding to model A1.As it is visible in the following graph visualization, it is not necessary to visualize the information if not required by the project needs (Fig. 6.2).Fig 6.2.Graph visualization of Vatican City, Biblioteca Apostolica Vaticana, Cerulli 374.3. Example 3 - Oxford, Bodleian Library, Bodleian Aeth. f. 11 (R) and Oxford, Bodleian Library, Bodleian Aeth. f. 12 (R)The case of Oxford, Bodleian Library, Bodleian Aeth. f. 11 (R) (Reule 2017a) and Oxford, Bodleian Library, Bodleian Aeth. f. 12 (R) (Reule 2017c) shows well the value of the triples for descriptions involving several entities, where traditionally we would have found a description with possibly a link to the other entity. It also demonstrates how the methodology in La Syntaxe could be used for manuscripts which are not a codex, for example, fragments of papyri or pieces of a stone inscription.The catalogue which is the source of the encoded catalogue entries for the manuscripts in Beta mau1e63u0101u1e25u01ddft says that both are scrolls containing magic prayers which belonged to the same owner and writes at the end of his description of Oxford, Bodleian Library, Bodleian Aeth. f. 11, Continuation in no. 91 where no. 91 is Oxford, Bodleian Library, Bodleian Aeth. f. 12. The research team has discussed this and convened that the two scrolls where once one.We know then of three UniCirc, the two we have in Bodleian Library and the one they once constituted.In our TEI descriptions we do not encode reconstructed manuscripts, so, we do not want a TEI record for the previously existing scroll composed of the current two.The annotations using SdC allow us to describe for each manuscript the transformation, which is of the type D3: division simple (Andrist, Canart, and Maniaci 2013, 69).All of the following statements could be given in the same TEI record, but in this case, some repetition is, although not necessary, useful considering that the user could start from either of the two entities in the TEI. The RDF produced by transforming the two XML encoded description is then indexed all together and the provenance of the triples is irrelevant.These will become triples as in the previous examples.Here we start by defining a UniCirc which is the outcome of the analytical process, the one we learn last about and only in our hypothesis.We assign to this reconstructed previous unique scroll the ID 'UniCirc1' (it could have been also UniCirc3, as long as unique in the file) and say that it underwent a transformation with ID 'tr1' which produced two UniCirc, 'UniCirc2' and 'UniCirc3'. Only then we say that UniCirc2 and UniCirc3 correspond to the current scrolls.This is repeated in the second scroll and generates a parallel set of ids and UniCirc, i.e. our BDLaethf11 is both BDLaethf11UniCircUniCirc3 and BDLaethf12UniCircUniCirc3.This looks and is redundant in this case.However, let us think of cases when the two sets of statements are produced independently.At some point, a researcher finds out that two units are part of the same story and the annotations will become much clearer with this further step in the research process only needing to equate the existing instances of transformation like in the example where BDLaethf12transformationtr1 is equated to BDLaethf11transformationtr1 with the property skos:exactMatch. This example shows also how phenomena involving more than one entity can be represented in RDF (Fig. 7.1), whereas they would need if only encoded in TEI a statement on each side with a pointer to the other.Fig 7.1.Graph visualization of Oxford, Bodleian Library, Bodleian Aeth. f. 11 (R) and Oxford, Bodleian Library, Bodleian Aeth. f. 12 (R)The Sankey charts here (Figs. 7.2 and 7.3) provide a very clear visualization of the division happening, different in Beta mau1e63u0101u1e25u01ddft according to the subject of the query.Fig 7.2. Sankey chart of Oxford, Bodleian Library, Bodleian Aeth. f. 11 (R)Fig 7.3.Sankey chart of Oxford, Bodleian Library, Bodleian Aeth. f. 12 (R)4.4.Example 4 - Paris, Bibliothu00e8que nationale de France, BnF u00c9thiopien 45 and Paris, Bibliothu00e8que nationale de France, BnF u00c9thiopien 165In this case we have in the catalogue entries about Paris, Bibliothu00e8que nationale de France, BnF u00c9thiopien 45 (Reule 2017b) and Paris, Bibliothu00e8que nationale de France, BnF u00c9thiopien 165 (Reule 2016a) a note which says that the latter (BNFet165) contains leaves detached from the former. This is not an uncommon event and in La Syntaxe is a multiple transformation MA1: mutilation d'un codex pour en accrou00eetre un autre [tr: mutilation of one codex to augment another] (Andrist, Canart, and Maniaci 2013, 72).51 Note that in the TEI description of BNFet45 there are a <msPart> with @xml:id='p1' and a <msFrag> with @xml:id='f2' which means that in this case we have this unit twice in the descriptions.In BNFet45 we will have the following <relation> elementst <listRelation>The difference from the previous example is in here that the transformation underwent by BNFet45 and that which affects BNFet165 are parts of a composite transformation. Using the property in the ontology dedicated to describing the relation between transformation sdc:isPartOfTransformation we can link the individually declared transformation and preserve knowledge about the complex event and its parts, to which a type can also be associated if needed (Fig. 8).This allows modelling multiple transformations as such and as parts.Fig 8.Sankey chart and La Syntaxe drawing of Paris, Bibliothu00e8que nationale de France, BnF u00c9thiopien 45 and Paris, Bibliothu00e8que nationale de France, BnF u00c9thiopien 1654.5. Example Application 1 - Grottaferrata, Exarchic Greek Abbey of St.Mary of Grottaferrata, Crypt.Aet. 7One of the aims of all this is to allow collaboration on the encoding and this example should show how the methodology can allow a codicological perspective to coexist with the encoding done from the angle of the book study and restoration.In Grottaferrata, Exarchic Greek Abbey of St Mary of Grottaferrata, Crypt. Aet. 7 (Dal Sasso 2018) the author of the description wanted to encode that there are traces of leather in the current binding, which tell us that the book was rebound.This is said in the description, but the information can be used to make a statement about the two UniCirc involved.This case can, however, be extended to say that not only the TEI encoding but also the RDF annotations offer levels of possible collaborations. Let us imagine for example the case of an annotation made on a manuscript image published by an institutional repository A, referring to another image published by an institutional repository The annotation could become relevant for the latter once a second scholar studies this from yet another perspective.The annotation could indeed be part of an entirely different project and be stored in a different location and still be accessible for reuse.4.6. Example Application 2 - Bern, Burgerbibliothek, Cod. 459In this last application example, we will take one of the cases discussed in La Syntaxe and try to encode it with the methodology described.The example is Bern, Burgerbibliothek, Cod. 459: Miscellanea, which is also available in TEI,52 and especially the description of its reconstruction as formulated in the example in the book (Andrist, Canart, and Maniaci 2013, 128u201329). Because the manuscript description is in TEI, and because our schema was defined looking also at this project as an example, I could take the XML file and use the transformation and visualization developed for Beta mau1e63u0101u1e25u01ddft without making any change to the file.It already had @xml:id attributes where needed (see above). I then directly added to that file the nodes which would represent the hypotheses made in the example and produced visualizations progressively as envisaged by the workflow. I will present the steps in the hypothesis formulation (Step 2 of the description above) and verification (Step 3) starting from the text of the example which presents progressively adding information five hypotheses (A to E).The authors start by presenting the tabular view of the manuscript (which is the descriptive part and is not reproduced here) and begin the analysis by saying...on ne peut que conclure u00e0 l'existence de trois UPH [tr: u2026 we cannot but conclude that three Hypothetic UniProd existed]which translates in the TEI encoding to the following triplesFig 9. Sankey Diagram of Bern, Burgerbibliothek, Cod. 459 UniProdThey then start with a first distinction of two possibilitiesle nombre d'UniCirc, par contre, est plus difficile u00e0 du00e9terminer, puisque, sur cette base, il n'est pas possible de du00e9cider entre les types de transformation - A1 ou A4 - subies par le codex [tr: the number of UniCirc, to the contrary, is more difficult to establish, because on the basis of these observations it is not possible to decide between the type of transformation A1 and A4 which the codex might have undergone]Hypothesis A is then formulated. I have split the text from the book in the XML code snippet to show exactly what in the authors' sentence is translated to a set of triplest<!--le codex actuel [tr : the current codex])-->tt<relation active=eCod_bbb-0459#UniCirc3a name=sdc:undergoesTransformation passive=eCod_bbb-0459#tr3a>The authors then state (Hypothesis C), i.e. that there might be mixes of the two transformation models A1 and A4, but do not formulate any of these and instead bring arguments for a Hypothesis D (Fig. 12). This is the same process as in the previous hypothesis but the UniProds were in different UniCirc, but we do not know the relation between them and those UniCirc, as Patrick Andrist clarified in a private conversation.Fig 12.Sankey Diagram of Hypothesis D for Bern, Burgerbibliothek, Cod. 459Note that in this example, the subjects of the transformation are directly the UniProd.However, there are more arguments from the observation that the author take into consideration to build on the previous hypothesis and formulate their final hypothesis, Hypothesis E (Fig. 13).Fig 13. Sankey Diagram of Hypothesis E for Bern, Burgerbibliothek, Cod. 459There is no reason other than the consistency of the visualization and the accuracy of the data encoded, not to provide all the above annotations together in the description.4.7.WorkflowNote that only basic inferences are made in the transformation and encoding, all the heuristic process and decision making on relevance, certainty and precision remain to the researcher. In the Beta mau1e63u0101u1e25u01ddft current workflow the encoder will make use of the web visualization or of other tables generated via the RDF data to make up their mind about each assertion and then encode it in the appropriate element, for example in a <relation> element with a statement-making use of the SdC ontology.The web visualization will support with the production of the table where he will be doing further analysis.The triple store will also offer the possibility to make further comparisons, searching via the SPARQL endpoint and visualizing results as graphs, charts or tables. For example, the researcher will be able to see all patterns available for a certain group of UniCirc (e.g. all UniCirc of a manuscript entity, or from an institution, etc.) and will be able to compare UniCirc which have similar patterns of discontinuities.If it is possible then, at any point in time for any researcher to add a statement to the encoding he will do so in the TEI file.The decision to make a certain statement certain will depend solely on the researcher assigning it to this class. Encoding in XML, transformation to RDF and visualization techniques play together in the research process closely following the methodology of La Syntaxe.5.Potential of Linked Open Data for ManuscriptsWe have seen how defining an ontology based on a specific methodology and producing triples based on XML encoding allows a project to achieve some research and encoding needs like the one of representing the complexity of the manuscript and give equivalent relevance to manuscripts we know have existed through traces of them in the presently survived ones. Let us conclude this contribution by stressing some further potential of Linked Open Data for manuscript research.The graph model provides the immediate benefit of being flexible and at the same time tying recorded aspects of a manuscript together using triples so that everything is linked and referenced. I want additionally to stress two aspects: the possibility to run federated queries and the connection possibilities provided by the use of common vocabularies.5.1. Federated queriesFederated Queries are a feature of SPARQL which allows 'executing queries distributed over different SPARQL endpoints.The SERVICE keyword (1) extends SPARQL 1.1 to support queries that merge data distributed across the Web' (Prud'hommeaux and Buil-Aranda 2013).53 In the example below, you can see an example of a federated query to the Syriaca RDF which can be run from the Beta mau1e63u0101u1e25u01ddft endpoint (the same could be done the other way around or from another endpoint, changing URI). It will return all works (lawd:ConceptualWork) in syriaca.org and in Beta mau1e63u0101u1e25u01ddft which have a relation to the Pleiades place 687928 (Jerusalem) which is the same as syriaca 104.The query in the example is different from a query to an aggregated triples store, like, e.g.Pelagios (Simon et al. 2014) where both projects share their data.Firstly, it queries the current status of the data, not the latest dump. Secondly, it requests data only from the specified dataset, not from all.In this example, the query unites the results because it assumes that both projects have triples of that kind.The usefulness of this would be for example in querying information about manuscripts held at the same institution, which are digitally scattered around several web resources, for example, a monastery had manuscripts in Ethiopic and Syriac which are now digitally available through the two projects. Besides the possibility of a relational database which would also easily allow retrieving a network of scribes owners and institutions, for example, there are more queries that we can ask.With a federated query, and the use of the above-described ontology one could for example query:by institution and type of transformation to plot how frequent a model of transformation is in different institutions (and of course one could do this on all data or only on a specific dataset).given a considerable and definite set of annotations to see patterns of transformation, e.g. if in a given time andor place there are more cases of a specific type of transformation.scribal habits analysis could be investigated by querying for transformations occurred in manuscripts of the same owner or by the same scribe.In general, a linked open data representation allows for queries across diverse resources, e.g. one could interrogate all versions of a given work in several traditions and the relative dating or ownership to support the study of text tradition and translation.5.2. Vocabularies and mappingsWe have described the use of an ontology to represent a specific type of information, but a further potential of the web of data lays in the relations which we cannot foresee.If I use a relation to a resource which other datasets point to, like the Pleiades place ID in the previous example, this is a first way to allow for these relations to surface, and the other way is to use the same vocabulary for the properties. When I define an ontology either other projects use my ontology or the ontology will not be useful to fetch any triples which make use of it without letting me know.It is thus always wise, if one wants to allow this kind of connections, to use existing vocabularies or, if none exists or satisfies the user needs, it is important to map it to other ontologies.For example, we could map the SdC ontology to entities and properties in CIDOC-CRM to allow CIDOC-CRM users to query our data in the way they expect it.A user with enough knowledge of the data and CIDOC-CRM could use the CONSTRUCT query form (see above) to produce the RDF in CIDOC-CRM he wants to be returned if he wants to consume that.One could also use the federation query to achieve this, implicitly mapping in the queryBut the external data might have a wider scope for crm:E18_Physical_Thing, which might have to be made more precise to have relevant results.Another option would be for the data provider to publish a mapping file or directly the CIDOC-CRM triples in the data.The above query example would return the same results because both triples exist. Here the assumptions are that a sdc:Transformation is always a crm:E11_Modification, but a user might want to make different mappings and would have to use the first method here presented.This is the method which Beta mau1e63u0101u1e25u01ddft is currently developing, to maintain in parallel also triples which construct valid CIDOC-CRM entities and properties.The implications of each of the above methods (by no means a complete list!) are not to be evaluated here, and I stress that they are implementation-dependent and not equivalent to one another. Each would also need a careful decision on how to align and interoperate with other resources, including with ones we might not know about but might be relevant to other researchers.All of the examples and methods appearing in this chapter are intended to illustrate at the very least that there are multiple options available and to present that fact as a strength of the LOD approach."
}